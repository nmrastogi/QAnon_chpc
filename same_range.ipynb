{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dotwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.5 or 10.5 5.56? What benis length is best? ...</td>\n",
       "      <td>1/7 twist. Range of projectile weights. All br...</td>\n",
       "      <td>scruffyusp</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meth took out the Christmas village way too ea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>salsashark</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m okay with this</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jaylaw</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Protestestors Get Emotional When Asked S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the_real_friend0rags</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Project Veritas - Absentee Ballot fraud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the_real_friend0rags</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Merry Wokemas!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phreedom</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Never-Trump Traitor of Humanity Kelly Loeffler...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TheImpossible1</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>I hope she gives a speech on women empowerment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kratomlol</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>#CNNRAW 9-8-20 from Project Veritas. 54 minute...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kratomlol</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Haroon Siddique (Guardian) engages in astonish...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AntonioOfVenice</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    14.5 or 10.5 5.56? What benis length is best? ...   \n",
       "1    Meth took out the Christmas village way too ea...   \n",
       "2                                   I’m okay with this   \n",
       "3    Trump Protestestors Get Emotional When Asked S...   \n",
       "4              Project Veritas - Absentee Ballot fraud   \n",
       "..                                                 ...   \n",
       "980                                     Merry Wokemas!   \n",
       "981  Never-Trump Traitor of Humanity Kelly Loeffler...   \n",
       "982  I hope she gives a speech on women empowerment...   \n",
       "983  #CNNRAW 9-8-20 from Project Veritas. 54 minute...   \n",
       "984  Haroon Siddique (Guardian) engages in astonish...   \n",
       "\n",
       "                                               content                author  \\\n",
       "0    1/7 twist. Range of projectile weights. All br...            scruffyusp   \n",
       "1                                                  NaN            salsashark   \n",
       "2                                                  NaN                jaylaw   \n",
       "3                                                  NaN  the_real_friend0rags   \n",
       "4                                                  NaN  the_real_friend0rags   \n",
       "..                                                 ...                   ...   \n",
       "980                                                NaN              Phreedom   \n",
       "981                                                NaN        TheImpossible1   \n",
       "982                                                NaN             kratomlol   \n",
       "983                                                NaN             kratomlol   \n",
       "984                                                NaN       AntonioOfVenice   \n",
       "\n",
       "                site  \n",
       "0      weekendgunnit  \n",
       "1      weekendgunnit  \n",
       "2       gavinmcinnes  \n",
       "3       gavinmcinnes  \n",
       "4       gavinmcinnes  \n",
       "..               ...  \n",
       "980  kotakuinaction2  \n",
       "981  kotakuinaction2  \n",
       "982  kotakuinaction2  \n",
       "983  kotakuinaction2  \n",
       "984  kotakuinaction2  \n",
       "\n",
       "[985 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/scratch/general/vast/u1472278/posts_range.csv\" \n",
    "posts=pd.read_csv(file_path)\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0\n",
       "content    701\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[['title', 'content']].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm down so long as automatics are cool too.\\n...</td>\n",
       "      <td>scruffyusp</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am into strong tall girls. I just think of t...</td>\n",
       "      <td>julyspy</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That guy about halfway though the vid had a YU...</td>\n",
       "      <td>Hillary_is_Satan</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.5</td>\n",
       "      <td>Geralt_of_Rivia1</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.5</td>\n",
       "      <td>Kappa</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>A stripper is always single if you throw enoug...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>MSM settled to avoid discovery.</td>\n",
       "      <td>TheImpossible1</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>These do not spark joy.\\nAnd by joy I mean ere...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>What a stupid fucking comment she’s clearly a ...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>In fact someone find photos of her poosi I wan...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6494 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content             author  \\\n",
       "0     I'm down so long as automatics are cool too.\\n...         scruffyusp   \n",
       "1     I am into strong tall girls. I just think of t...            julyspy   \n",
       "2     That guy about halfway though the vid had a YU...   Hillary_is_Satan   \n",
       "3                                                  11.5   Geralt_of_Rivia1   \n",
       "4                                                  12.5              Kappa   \n",
       "...                                                 ...                ...   \n",
       "6489  A stripper is always single if you throw enoug...  Liberatevia300AAC   \n",
       "6490                    MSM settled to avoid discovery.     TheImpossible1   \n",
       "6491  These do not spark joy.\\nAnd by joy I mean ere...  Liberatevia300AAC   \n",
       "6492  What a stupid fucking comment she’s clearly a ...  Liberatevia300AAC   \n",
       "6493  In fact someone find photos of her poosi I wan...  Liberatevia300AAC   \n",
       "\n",
       "                 site  \n",
       "0       weekendgunnit  \n",
       "1        gavinmcinnes  \n",
       "2        gavinmcinnes  \n",
       "3       weekendgunnit  \n",
       "4       weekendgunnit  \n",
       "...               ...  \n",
       "6489    weekendgunnit  \n",
       "6490  kotakuinaction2  \n",
       "6491    weekendgunnit  \n",
       "6492    weekendgunnit  \n",
       "6493    weekendgunnit  \n",
       "\n",
       "[6494 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/scratch/general/vast/u1472278/comments_range.csv\" \n",
    "comments=pd.read_csv(file_path)\n",
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.5 or 10.5 5.56? What benis length is best? ...</td>\n",
       "      <td>1/7 twist. Range of projectile weights. All br...</td>\n",
       "      <td>scruffyusp</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meth took out the Christmas village way too ea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>salsashark</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m okay with this</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jaylaw</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Protestestors Get Emotional When Asked S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the_real_friend0rags</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Project Veritas - Absentee Ballot fraud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the_real_friend0rags</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Merry Wokemas!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phreedom</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Never-Trump Traitor of Humanity Kelly Loeffler...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TheImpossible1</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>I hope she gives a speech on women empowerment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kratomlol</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>#CNNRAW 9-8-20 from Project Veritas. 54 minute...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kratomlol</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Haroon Siddique (Guardian) engages in astonish...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AntonioOfVenice</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    14.5 or 10.5 5.56? What benis length is best? ...   \n",
       "1    Meth took out the Christmas village way too ea...   \n",
       "2                                   I’m okay with this   \n",
       "3    Trump Protestestors Get Emotional When Asked S...   \n",
       "4              Project Veritas - Absentee Ballot fraud   \n",
       "..                                                 ...   \n",
       "980                                     Merry Wokemas!   \n",
       "981  Never-Trump Traitor of Humanity Kelly Loeffler...   \n",
       "982  I hope she gives a speech on women empowerment...   \n",
       "983  #CNNRAW 9-8-20 from Project Veritas. 54 minute...   \n",
       "984  Haroon Siddique (Guardian) engages in astonish...   \n",
       "\n",
       "                                               content                author  \\\n",
       "0    1/7 twist. Range of projectile weights. All br...            scruffyusp   \n",
       "1                                                  NaN            salsashark   \n",
       "2                                                  NaN                jaylaw   \n",
       "3                                                  NaN  the_real_friend0rags   \n",
       "4                                                  NaN  the_real_friend0rags   \n",
       "..                                                 ...                   ...   \n",
       "980                                                NaN              Phreedom   \n",
       "981                                                NaN        TheImpossible1   \n",
       "982                                                NaN             kratomlol   \n",
       "983                                                NaN             kratomlol   \n",
       "984                                                NaN       AntonioOfVenice   \n",
       "\n",
       "                site  \n",
       "0      weekendgunnit  \n",
       "1      weekendgunnit  \n",
       "2       gavinmcinnes  \n",
       "3       gavinmcinnes  \n",
       "4       gavinmcinnes  \n",
       "..               ...  \n",
       "980  kotakuinaction2  \n",
       "981  kotakuinaction2  \n",
       "982  kotakuinaction2  \n",
       "983  kotakuinaction2  \n",
       "984  kotakuinaction2  \n",
       "\n",
       "[985 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=posts\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.5 or 10.5 5.56? What benis length is best? ...</td>\n",
       "      <td>1/7 twist. Range of projectile weights. All br...</td>\n",
       "      <td>scruffyusp</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meth took out the Christmas village way too ea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>salsashark</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m okay with this</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jaylaw</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Protestestors Get Emotional When Asked S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the_real_friend0rags</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Project Veritas - Absentee Ballot fraud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the_real_friend0rags</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Merry Wokemas!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phreedom</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Never-Trump Traitor of Humanity Kelly Loeffler...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TheImpossible1</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>I hope she gives a speech on women empowerment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kratomlol</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>#CNNRAW 9-8-20 from Project Veritas. 54 minute...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kratomlol</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Haroon Siddique (Guardian) engages in astonish...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AntonioOfVenice</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    14.5 or 10.5 5.56? What benis length is best? ...   \n",
       "1    Meth took out the Christmas village way too ea...   \n",
       "2                                   I’m okay with this   \n",
       "3    Trump Protestestors Get Emotional When Asked S...   \n",
       "4              Project Veritas - Absentee Ballot fraud   \n",
       "..                                                 ...   \n",
       "980                                     Merry Wokemas!   \n",
       "981  Never-Trump Traitor of Humanity Kelly Loeffler...   \n",
       "982  I hope she gives a speech on women empowerment...   \n",
       "983  #CNNRAW 9-8-20 from Project Veritas. 54 minute...   \n",
       "984  Haroon Siddique (Guardian) engages in astonish...   \n",
       "\n",
       "                                               content                author  \\\n",
       "0    1/7 twist. Range of projectile weights. All br...            scruffyusp   \n",
       "1                                                  NaN            salsashark   \n",
       "2                                                  NaN                jaylaw   \n",
       "3                                                  NaN  the_real_friend0rags   \n",
       "4                                                  NaN  the_real_friend0rags   \n",
       "..                                                 ...                   ...   \n",
       "980                                                NaN              Phreedom   \n",
       "981                                                NaN        TheImpossible1   \n",
       "982                                                NaN             kratomlol   \n",
       "983                                                NaN             kratomlol   \n",
       "984                                                NaN       AntonioOfVenice   \n",
       "\n",
       "                site  \n",
       "0      weekendgunnit  \n",
       "1      weekendgunnit  \n",
       "2       gavinmcinnes  \n",
       "3       gavinmcinnes  \n",
       "4       gavinmcinnes  \n",
       "..               ...  \n",
       "980  kotakuinaction2  \n",
       "981  kotakuinaction2  \n",
       "982  kotakuinaction2  \n",
       "983  kotakuinaction2  \n",
       "984  kotakuinaction2  \n",
       "\n",
       "[985 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Step 1: Remove rows where both 'title' and 'content' are NaN or empty\n",
    "df_cleaned = df.dropna(subset=['title', 'content'], how='all')  # Drop if both are NaN\n",
    "df_cleaned = df_cleaned[~((df_cleaned['title'].fillna('').str.strip() == '') &\n",
    "                          (df_cleaned['content'].fillna('').str.strip() == ''))]  # Drop if both are empty strings\n",
    "\n",
    "# Step 2: Remove rows with links in both 'title' and 'content'\n",
    "has_link = df_cleaned['title'].fillna('').str.contains(r'http[s]?://\\S+', na=False) & \\\n",
    "           df_cleaned['content'].fillna('').str.contains(r'http[s]?://\\S+', na=False)\n",
    "df_cleaned = df_cleaned[~has_link]\n",
    "\n",
    "# Reset the index of the dataframe\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "\n",
    "df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.5 or 10.5 5.56? What benis length is best? ...</td>\n",
       "      <td>1/7 twist. Range of projectile weights. All br...</td>\n",
       "      <td>scruffyusp</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meth took out the Christmas village way too ea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>salsashark</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m okay with this</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jaylaw</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Protestestors Get Emotional When Asked S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the_real_friend0rags</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Project Veritas - Absentee Ballot fraud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the_real_friend0rags</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Merry Wokemas!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phreedom</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Never-Trump Traitor of Humanity Kelly Loeffler...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TheImpossible1</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>I hope she gives a speech on women empowerment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kratomlol</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>#CNNRAW 9-8-20 from Project Veritas. 54 minute...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kratomlol</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Haroon Siddique (Guardian) engages in astonish...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AntonioOfVenice</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    14.5 or 10.5 5.56? What benis length is best? ...   \n",
       "1    Meth took out the Christmas village way too ea...   \n",
       "2                                   I’m okay with this   \n",
       "3    Trump Protestestors Get Emotional When Asked S...   \n",
       "4              Project Veritas - Absentee Ballot fraud   \n",
       "..                                                 ...   \n",
       "980                                     Merry Wokemas!   \n",
       "981  Never-Trump Traitor of Humanity Kelly Loeffler...   \n",
       "982  I hope she gives a speech on women empowerment...   \n",
       "983  #CNNRAW 9-8-20 from Project Veritas. 54 minute...   \n",
       "984  Haroon Siddique (Guardian) engages in astonish...   \n",
       "\n",
       "                                               content                author  \\\n",
       "0    1/7 twist. Range of projectile weights. All br...            scruffyusp   \n",
       "1                                                  NaN            salsashark   \n",
       "2                                                  NaN                jaylaw   \n",
       "3                                                  NaN  the_real_friend0rags   \n",
       "4                                                  NaN  the_real_friend0rags   \n",
       "..                                                 ...                   ...   \n",
       "980                                                NaN              Phreedom   \n",
       "981                                                NaN        TheImpossible1   \n",
       "982                                                NaN             kratomlol   \n",
       "983                                                NaN             kratomlol   \n",
       "984                                                NaN       AntonioOfVenice   \n",
       "\n",
       "                site  \n",
       "0      weekendgunnit  \n",
       "1      weekendgunnit  \n",
       "2       gavinmcinnes  \n",
       "3       gavinmcinnes  \n",
       "4       gavinmcinnes  \n",
       "..               ...  \n",
       "980  kotakuinaction2  \n",
       "981  kotakuinaction2  \n",
       "982  kotakuinaction2  \n",
       "983  kotakuinaction2  \n",
       "984  kotakuinaction2  \n",
       "\n",
       "[985 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_cleaned\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /uufs/chpc.utah.edu/common/home/u1472278/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens from title and content: 26110\n",
      "Total combined category counts for both 'title' and 'content' columns:\n",
      "fusion                    27\n",
      "violence                  67\n",
      "identification1            0\n",
      "identification2            0\n",
      "slurs                     13\n",
      "demonisation              31\n",
      "dehumanisation            35\n",
      "existential_threat        13\n",
      "conspiracy                57\n",
      "inevitable_war1           33\n",
      "inevitable_war2           54\n",
      "violence_justification     5\n",
      "martyr                     1\n",
      "violent_role_model1        6\n",
      "violent_role_model2       19\n",
      "hopelessness1             46\n",
      "hopelessness2             22\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download NLTK stopwords if you haven't already\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load NLTK English stopwords\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Sample dictionaries (you can add more or modify as needed)\n",
    "fusion = [\"brother\", \"sister\", \"family\", \"motherland\", \"our blood\", \"fatherland\", \"sons\", \"daughters\", \"kin\", \"my people\", \"my race\", \"our people\", \"European race\", \"ancestry\", \"ancestor\", \"descendant\", \"fellow\", \"brethren\", \"comrades\"]\n",
    "violence = [\"kill\", \"hang\", \"bomb\", \"shoot\", \"slaughter\", \"execute\", \"execution\", \"punish\", \"death penalty\", \"massacre\", \"destroy\", \"must attack\", \"must fight\", \"revenge\", \"retribution\", \"eradicate\", \"starve\", \"die\", \"torture\", \"behead\", \"burn\", \"bring death to\", \"give them hell\", \"weapon\", \"firearm\", \"assassinate\", \"gun\", \"rifle\", \"knife\", \"grenade\", \"brutal steps\", \"molotov\", \"jihaad\", \"jihad\", \"set fire\", \"revolution\", \"forcible overthrow\", \"flamethrowers\", \"M1-16\", \"ammonium nitrate\"]\n",
    "identification1 = [\"\\\\bwe\\\\b\", \"\\\\bus\\\\b\", \"\\\\bour\\\\b\", \"\\\\bthey\\\\b\", \"\\\\bthem\\\\b\", \"\\\\btheir\\\\b\"]\n",
    "identification2 = [\"\\\\bI\\\\b\", \"\\\\bme\\\\b\", \"\\\\bmy\\\\b\", \"\\\\byou\\\\b\", \"\\\\byour\\\\b\"]\n",
    "slurs = [\"kike\", \"nigger\", \"negro\", \"dirty jew\", \"spic\", \"fag\", \"goyim\", \"golem\", \"the jew\", \"global jewry\", \"pajeet\", \"bitch\", \"whore\"]\n",
    "demonisation = [\"traitor\", \"evil\", \"enemy\", \"corrupt\", \"vicious\", \"barbaric\", \"depraved\", \"vile\", \"puppets\", \"perversion\", \"blood libel\", \"pervert\", \"pedo\", \"crime\", \"cruel\", \"bloody\", \"genocidal\", \"sinful\", \"deceitful\", \"invader\", \"poison\", \"parasite\", \"menace\", \"brutal\", \"ruthless\", \"bloodsucking\", \"dirty\", \"deceptive\", \"treacherous\", \"poisonous\", \"oppressive\", \"oppressor\", \"shird\", \"unbeliever\", \"immoral\", \"jahili\", \"pollute\", \"demolish\", \"shake the foundations\", \"dar ul-harb\", \"arrogant\", \"mischievous\", \"criminal\", \"deceivers\", \"liars\"]\n",
    "dehumanisation = [\"animal\", \"plague\", \"impure\", \"brute\", \"dog\", \"lower iq\", \"lower being\", \"inferior\", \"squalid\", \"parasitic\", \"parasite\", \"creature\", \"trash\", \"filth\", \"vermin\", \"spider\", \"devil\", \"monster\", \"beast\", \"reptile\", \"reptiloid\", \"femoid\", \"reptilian\", \"snake\", \"cockroach\", \"beneath human skin\", \"sub human\", \"anti-human\", \"disease\", \"savage\", \"infest\", \"breed\", \"locust\", \"monkey\", \"gorilla\", \"rat\", \"microbe\", \"satan\", \"cancer\", \"scum\"]\n",
    "existential_threat = [\"subjected to\", \"coerced\", \"brainwashed\", \"exterminated\", \"brutalised\", \"raped\", \"terrorised\", \"ravaged\", \"extinction\", \"replacement\", \"genocide\", \"robbed\", \"subjugate\", \"make war upon my people\", \"destroy\", \"subvert\", \"overwhelmed\", \"under siege\", \"demographic siege\", \"disenfranchise\", \"assault\", \"kill us\", \"kill our\", \"kill my\", \"running out of time\", \"run out of time\", \"last chance\", \"enslavement\", \"enslaved\", \"suffer\", \"plunder\", \"condemned to death\", \"destruction of all mankind\", \"at the brink of\", \"endanger\", \"annihilation\", \"decay\"]\n",
    "conspiracy = [\"betray\", \"betrayal\", \"sell\", \"sold\", \"collude\", \"conspire\", \"fake\", \"fraud\", \"corruption\", \"corrupt\", \"zog\", \"great replacement\", \"white genocide\", \"kalergi\", \"pedo elites\", \"NWO\", \"illuminati\", \"inside job\", \"Eurabia\"]\n",
    "inevitable_war1 = [\"war\", \"battle\", \"fight\", \"jihad\", \"jihaad\", \"collapse\", \"conflict\"]\n",
    "inevitable_war2 = [\"imminent\", \"inevitable\", \"looming\", \"start\", \"begin\", \"already\", \"heading for\", \"ongoing\", \"stage\", \"phase\", \"when\", \"has been\", \"likely\", \"predict\", \"expect\", \"will happen\", \"has begun\", \"current\", \"impending\"]\n",
    "violence_justification = [\"pre-emptive\", \"defend\", \"protect\", \"self-defense\", \"self-defence\", \"forced to fight\", \"no longer ignore\", \"act of defense\", \"purified\", \"purify\", \"need for war\", \"need for violence\", \"need for jihad\", \"struggle is imposed\", \"natural struggle\", \"cannot co-exist\"]\n",
    "martyr = [\"die in glory\", \"sacrifice\", \"knight\", \"martyr\", \"die selflessly\", \"protecting our people\", \"immortal\", \"preserve\", \"act of preservation\", \"defend the world of the Lord\", \"defending the work of the Lord\", \"stand guard\", \"standing guard\", \"the herald\", \"release mankind from\", \"free from\", \"freed from\"]\n",
    "violent_role_model1 = [\"breivik\", \"tarrant\", \"hitler\", \"crusius\", \"rodger\", \"baillet\", \"earnest\", \"minassian\", \"mcveigh\", \"christchurch\", \"poway\", \"el paso\"]\n",
    "violent_role_model2 = [\"hero\", \"role model\", \"saint\", \"inspire\", \"inspiration\", \"inspiring\", \"support\", \"influenced\"]\n",
    "hopelessness1 = [\"democracy\", \"democratic\", \"peaceful\", \"political\", \"system\", \"politics\", \"dialogue\", \"passivity\"]\n",
    "hopelessness2 = [\"meaningless\", \"weak\", \"fail\", \"end\", \"vanish\", \"man-made\", \"flawed\", \"jahili\", \"given up\"]\n",
    "# Add other dictionaries if needed, similar to the ones above\n",
    "\n",
    "# Add all dictionaries to a list for easier processing\n",
    "dictionaries = {\n",
    "    'fusion': fusion,\n",
    "    'violence': violence,\n",
    "    'identification1': identification1,\n",
    "    'identification2': identification2,\n",
    "    'slurs': slurs,\n",
    "    'demonisation': demonisation,\n",
    "    'dehumanisation': dehumanisation,\n",
    "    'existential_threat': existential_threat,\n",
    "    'conspiracy': conspiracy,\n",
    "    'inevitable_war1': inevitable_war1,\n",
    "    'inevitable_war2': inevitable_war2,\n",
    "    'violence_justification': violence_justification,\n",
    "    'martyr': martyr,\n",
    "    'violent_role_model1': violent_role_model1,\n",
    "    'violent_role_model2': violent_role_model2,\n",
    "    'hopelessness1': hopelessness1,\n",
    "    'hopelessness2': hopelessness2\n",
    "}\n",
    "\n",
    "# Pre-compile regex patterns for each dictionary to improve performance\n",
    "compiled_patterns = {category: [re.compile(rf'\\b{re.escape(word)}\\b') for word in words_list]\n",
    "                     for category, words_list in dictionaries.items()}\n",
    "\n",
    "# Function to clean text: remove stop words and lower the text\n",
    "def clean_text(text):\n",
    "    # Convert non-string values to an empty string\n",
    "    if not isinstance(text, str):\n",
    "        text = ''\n",
    "    words = text.split()\n",
    "    cleaned_words = [word.lower() for word in words if word.lower() not in nltk_stopwords]\n",
    "    return ' '.join(cleaned_words)\n",
    "\n",
    "# Function to count occurrences from each dictionary in the text\n",
    "def count_categories(text):\n",
    "    category_counts = {category: 0 for category in dictionaries}  # Initialize counts\n",
    "    for category, patterns in compiled_patterns.items():\n",
    "        for pattern in patterns:\n",
    "            if pattern.search(text):\n",
    "                category_counts[category] += 1\n",
    "    return category_counts\n",
    "\n",
    "# Function to count the number of tokens (words) in cleaned text\n",
    "def count_tokens(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Sample dataframe\n",
    "\n",
    "\n",
    "# Clean the text in the columns\n",
    "df['title_cleaned'] = df['title'].apply(clean_text)\n",
    "df['content_cleaned'] = df['content'].apply(clean_text)\n",
    "\n",
    "# Count occurrences of each category in the cleaned text\n",
    "df['title_category_counts'] = df['title_cleaned'].apply(count_categories)\n",
    "df['content_category_counts'] = df['content_cleaned'].apply(count_categories)\n",
    "\n",
    "# Combine the counts for both title and content columns\n",
    "df['combined_category_counts'] = df.apply(lambda row: {category: row['title_category_counts'][category] + row['content_category_counts'][category]\n",
    "                                                       for category in dictionaries}, axis=1)\n",
    "\n",
    "# Count the total number of tokens in both title and content\n",
    "df['title_token_count'] = df['title_cleaned'].apply(count_tokens)\n",
    "df['content_token_count'] = df['content_cleaned'].apply(count_tokens)\n",
    "\n",
    "# Calculate the total number of tokens from the entire DataFrame\n",
    "total_tokens = df['title_token_count'].sum() + df['content_token_count'].sum()\n",
    "\n",
    "# Print the total number of tokens\n",
    "print(f\"Total number of tokens from title and content: {total_tokens}\")\n",
    "\n",
    "# Print the final combined category counts for both columns\n",
    "combined_category_counts_total = df['combined_category_counts'].apply(pd.Series).sum()\n",
    "print(\"Total combined category counts for both 'title' and 'content' columns:\")\n",
    "print(combined_category_counts_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens BEFORE cleaning: 42337\n",
      "Total number of tokens AFTER cleaning: 26110\n"
     ]
    }
   ],
   "source": [
    "# Function to count tokens in raw (unprocessed) text\n",
    "def count_raw_tokens(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "# Count raw tokens before cleaning\n",
    "df['title_raw_token_count'] = df['title'].apply(count_raw_tokens)\n",
    "df['content_raw_token_count'] = df['content'].apply(count_raw_tokens)\n",
    "\n",
    "# Total tokens before cleaning\n",
    "total_raw_tokens = df['title_raw_token_count'].sum() + df['content_raw_token_count'].sum()\n",
    "\n",
    "# Total tokens after cleaning (already done in your code)\n",
    "total_cleaned_tokens = df['title_token_count'].sum() + df['content_token_count'].sum()\n",
    "\n",
    "# Print both\n",
    "print(f\"Total number of tokens BEFORE cleaning: {total_raw_tokens}\")\n",
    "print(f\"Total number of tokens AFTER cleaning: {total_cleaned_tokens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm down so long as automatics are cool too.\\n...</td>\n",
       "      <td>scruffyusp</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am into strong tall girls. I just think of t...</td>\n",
       "      <td>julyspy</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That guy about halfway though the vid had a YU...</td>\n",
       "      <td>Hillary_is_Satan</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.5</td>\n",
       "      <td>Geralt_of_Rivia1</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.5</td>\n",
       "      <td>Kappa</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>A stripper is always single if you throw enoug...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>MSM settled to avoid discovery.</td>\n",
       "      <td>TheImpossible1</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>These do not spark joy.\\nAnd by joy I mean ere...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>What a stupid fucking comment she’s clearly a ...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>In fact someone find photos of her poosi I wan...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6494 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content             author  \\\n",
       "0     I'm down so long as automatics are cool too.\\n...         scruffyusp   \n",
       "1     I am into strong tall girls. I just think of t...            julyspy   \n",
       "2     That guy about halfway though the vid had a YU...   Hillary_is_Satan   \n",
       "3                                                  11.5   Geralt_of_Rivia1   \n",
       "4                                                  12.5              Kappa   \n",
       "...                                                 ...                ...   \n",
       "6489  A stripper is always single if you throw enoug...  Liberatevia300AAC   \n",
       "6490                    MSM settled to avoid discovery.     TheImpossible1   \n",
       "6491  These do not spark joy.\\nAnd by joy I mean ere...  Liberatevia300AAC   \n",
       "6492  What a stupid fucking comment she’s clearly a ...  Liberatevia300AAC   \n",
       "6493  In fact someone find photos of her poosi I wan...  Liberatevia300AAC   \n",
       "\n",
       "                 site  \n",
       "0       weekendgunnit  \n",
       "1        gavinmcinnes  \n",
       "2        gavinmcinnes  \n",
       "3       weekendgunnit  \n",
       "4       weekendgunnit  \n",
       "...               ...  \n",
       "6489    weekendgunnit  \n",
       "6490  kotakuinaction2  \n",
       "6491    weekendgunnit  \n",
       "6492    weekendgunnit  \n",
       "6493    weekendgunnit  \n",
       "\n",
       "[6494 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/scratch/general/vast/u1472278/comments_range.csv\" \n",
    "comments=pd.read_csv(file_path)\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm down so long as automatics are cool too.\\n...</td>\n",
       "      <td>scruffyusp</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am into strong tall girls. I just think of t...</td>\n",
       "      <td>julyspy</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That guy about halfway though the vid had a YU...</td>\n",
       "      <td>Hillary_is_Satan</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.5</td>\n",
       "      <td>Geralt_of_Rivia1</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.5</td>\n",
       "      <td>Kappa</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>A stripper is always single if you throw enoug...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>MSM settled to avoid discovery.</td>\n",
       "      <td>TheImpossible1</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>These do not spark joy.\\nAnd by joy I mean ere...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>What a stupid fucking comment she’s clearly a ...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>In fact someone find photos of her poosi I wan...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6494 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content             author  \\\n",
       "0     I'm down so long as automatics are cool too.\\n...         scruffyusp   \n",
       "1     I am into strong tall girls. I just think of t...            julyspy   \n",
       "2     That guy about halfway though the vid had a YU...   Hillary_is_Satan   \n",
       "3                                                  11.5   Geralt_of_Rivia1   \n",
       "4                                                  12.5              Kappa   \n",
       "...                                                 ...                ...   \n",
       "6489  A stripper is always single if you throw enoug...  Liberatevia300AAC   \n",
       "6490                    MSM settled to avoid discovery.     TheImpossible1   \n",
       "6491  These do not spark joy.\\nAnd by joy I mean ere...  Liberatevia300AAC   \n",
       "6492  What a stupid fucking comment she’s clearly a ...  Liberatevia300AAC   \n",
       "6493  In fact someone find photos of her poosi I wan...  Liberatevia300AAC   \n",
       "\n",
       "                 site  \n",
       "0       weekendgunnit  \n",
       "1        gavinmcinnes  \n",
       "2        gavinmcinnes  \n",
       "3       weekendgunnit  \n",
       "4       weekendgunnit  \n",
       "...               ...  \n",
       "6489    weekendgunnit  \n",
       "6490  kotakuinaction2  \n",
       "6491    weekendgunnit  \n",
       "6492    weekendgunnit  \n",
       "6493    weekendgunnit  \n",
       "\n",
       "[6494 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=comments\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm down so long as automatics are cool too.\\n...</td>\n",
       "      <td>scruffyusp</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am into strong tall girls. I just think of t...</td>\n",
       "      <td>julyspy</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That guy about halfway though the vid had a YU...</td>\n",
       "      <td>Hillary_is_Satan</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.5</td>\n",
       "      <td>Geralt_of_Rivia1</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.5</td>\n",
       "      <td>Kappa</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>A stripper is always single if you throw enoug...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6281</th>\n",
       "      <td>MSM settled to avoid discovery.</td>\n",
       "      <td>TheImpossible1</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6282</th>\n",
       "      <td>These do not spark joy.\\nAnd by joy I mean ere...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6283</th>\n",
       "      <td>What a stupid fucking comment she’s clearly a ...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6284</th>\n",
       "      <td>In fact someone find photos of her poosi I wan...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6285 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content             author  \\\n",
       "0     I'm down so long as automatics are cool too.\\n...         scruffyusp   \n",
       "1     I am into strong tall girls. I just think of t...            julyspy   \n",
       "2     That guy about halfway though the vid had a YU...   Hillary_is_Satan   \n",
       "3                                                  11.5   Geralt_of_Rivia1   \n",
       "4                                                  12.5              Kappa   \n",
       "...                                                 ...                ...   \n",
       "6280  A stripper is always single if you throw enoug...  Liberatevia300AAC   \n",
       "6281                    MSM settled to avoid discovery.     TheImpossible1   \n",
       "6282  These do not spark joy.\\nAnd by joy I mean ere...  Liberatevia300AAC   \n",
       "6283  What a stupid fucking comment she’s clearly a ...  Liberatevia300AAC   \n",
       "6284  In fact someone find photos of her poosi I wan...  Liberatevia300AAC   \n",
       "\n",
       "                 site  \n",
       "0       weekendgunnit  \n",
       "1        gavinmcinnes  \n",
       "2        gavinmcinnes  \n",
       "3       weekendgunnit  \n",
       "4       weekendgunnit  \n",
       "...               ...  \n",
       "6280    weekendgunnit  \n",
       "6281  kotakuinaction2  \n",
       "6282    weekendgunnit  \n",
       "6283    weekendgunnit  \n",
       "6284    weekendgunnit  \n",
       "\n",
       "[6285 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Step 1: Remove rows where both 'title' and 'content' are NaN or empty\n",
    "df_cleaned = df.dropna(subset=['content'], how='all')  # Drop rows only if both are NaN\n",
    "df_cleaned = df_cleaned[(df_cleaned['content'].str.strip() != '')]  # Keep rows if either column has text\n",
    "\n",
    "# Step 2: Remove rows with links in both 'title' and 'content' (detecting links using regex)\n",
    "df_cleaned = df_cleaned[~df_cleaned['content'].str.contains(r'http[s]?://\\S+', na=False)]\n",
    "\n",
    "# Reset the index of the dataframe\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm down so long as automatics are cool too.\\n...</td>\n",
       "      <td>scruffyusp</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am into strong tall girls. I just think of t...</td>\n",
       "      <td>julyspy</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That guy about halfway though the vid had a YU...</td>\n",
       "      <td>Hillary_is_Satan</td>\n",
       "      <td>gavinmcinnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.5</td>\n",
       "      <td>Geralt_of_Rivia1</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.5</td>\n",
       "      <td>Kappa</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>A stripper is always single if you throw enoug...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6281</th>\n",
       "      <td>MSM settled to avoid discovery.</td>\n",
       "      <td>TheImpossible1</td>\n",
       "      <td>kotakuinaction2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6282</th>\n",
       "      <td>These do not spark joy.\\nAnd by joy I mean ere...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6283</th>\n",
       "      <td>What a stupid fucking comment she’s clearly a ...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6284</th>\n",
       "      <td>In fact someone find photos of her poosi I wan...</td>\n",
       "      <td>Liberatevia300AAC</td>\n",
       "      <td>weekendgunnit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6285 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content             author  \\\n",
       "0     I'm down so long as automatics are cool too.\\n...         scruffyusp   \n",
       "1     I am into strong tall girls. I just think of t...            julyspy   \n",
       "2     That guy about halfway though the vid had a YU...   Hillary_is_Satan   \n",
       "3                                                  11.5   Geralt_of_Rivia1   \n",
       "4                                                  12.5              Kappa   \n",
       "...                                                 ...                ...   \n",
       "6280  A stripper is always single if you throw enoug...  Liberatevia300AAC   \n",
       "6281                    MSM settled to avoid discovery.     TheImpossible1   \n",
       "6282  These do not spark joy.\\nAnd by joy I mean ere...  Liberatevia300AAC   \n",
       "6283  What a stupid fucking comment she’s clearly a ...  Liberatevia300AAC   \n",
       "6284  In fact someone find photos of her poosi I wan...  Liberatevia300AAC   \n",
       "\n",
       "                 site  \n",
       "0       weekendgunnit  \n",
       "1        gavinmcinnes  \n",
       "2        gavinmcinnes  \n",
       "3       weekendgunnit  \n",
       "4       weekendgunnit  \n",
       "...               ...  \n",
       "6280    weekendgunnit  \n",
       "6281  kotakuinaction2  \n",
       "6282    weekendgunnit  \n",
       "6283    weekendgunnit  \n",
       "6284    weekendgunnit  \n",
       "\n",
       "[6285 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_cleaned\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /uufs/chpc.utah.edu/common/home/u1472278/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in 'content' BEFORE cleaning: 207491\n",
      "Total number of tokens in 'content' AFTER cleaning: 112604\n",
      "Total combined category counts in 'content' column:\n",
      "fusion                     99\n",
      "violence                  491\n",
      "identification1             0\n",
      "identification2             0\n",
      "slurs                      56\n",
      "demonisation              185\n",
      "dehumanisation            140\n",
      "existential_threat         86\n",
      "conspiracy                154\n",
      "inevitable_war1           157\n",
      "inevitable_war2           407\n",
      "violence_justification     55\n",
      "martyr                      7\n",
      "violent_role_model1        19\n",
      "violent_role_model2        74\n",
      "hopelessness1             207\n",
      "hopelessness2             116\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download NLTK stopwords if you haven't already\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load NLTK English stopwords\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Sample dictionaries (you can add more or modify as needed)\n",
    "fusion = [\"brother\", \"sister\", \"family\", \"motherland\", \"our blood\", \"fatherland\", \"sons\", \"daughters\", \"kin\", \"my people\", \"my race\", \"our people\", \"European race\", \"ancestry\", \"ancestor\", \"descendant\", \"fellow\", \"brethren\", \"comrades\"]\n",
    "violence = [\"kill\", \"hang\", \"bomb\", \"shoot\", \"slaughter\", \"execute\", \"execution\", \"punish\", \"death penalty\", \"massacre\", \"destroy\", \"must attack\", \"must fight\", \"revenge\", \"retribution\", \"eradicate\", \"starve\", \"die\", \"torture\", \"behead\", \"burn\", \"bring death to\", \"give them hell\", \"weapon\", \"firearm\", \"assassinate\", \"gun\", \"rifle\", \"knife\", \"grenade\", \"brutal steps\", \"molotov\", \"jihaad\", \"jihad\", \"set fire\", \"revolution\", \"forcible overthrow\", \"flamethrowers\", \"M1-16\", \"ammonium nitrate\"]\n",
    "identification1 = [\"\\\\bwe\\\\b\", \"\\\\bus\\\\b\", \"\\\\bour\\\\b\", \"\\\\bthey\\\\b\", \"\\\\bthem\\\\b\", \"\\\\btheir\\\\b\"]\n",
    "identification2 = [\"\\\\bI\\\\b\", \"\\\\bme\\\\b\", \"\\\\bmy\\\\b\", \"\\\\byou\\\\b\", \"\\\\byour\\\\b\"]\n",
    "slurs = [\"kike\", \"nigger\", \"negro\", \"dirty jew\", \"spic\", \"fag\", \"goyim\", \"golem\", \"the jew\", \"global jewry\", \"pajeet\", \"bitch\", \"whore\"]\n",
    "demonisation = [\"traitor\", \"evil\", \"enemy\", \"corrupt\", \"vicious\", \"barbaric\", \"depraved\", \"vile\", \"puppets\", \"perversion\", \"blood libel\", \"pervert\", \"pedo\", \"crime\", \"cruel\", \"bloody\", \"genocidal\", \"sinful\", \"deceitful\", \"invader\", \"poison\", \"parasite\", \"menace\", \"brutal\", \"ruthless\", \"bloodsucking\", \"dirty\", \"deceptive\", \"treacherous\", \"poisonous\", \"oppressive\", \"oppressor\", \"shird\", \"unbeliever\", \"immoral\", \"jahili\", \"pollute\", \"demolish\", \"shake the foundations\", \"dar ul-harb\", \"arrogant\", \"mischievous\", \"criminal\", \"deceivers\", \"liars\"]\n",
    "dehumanisation = [\"animal\", \"plague\", \"impure\", \"brute\", \"dog\", \"lower iq\", \"lower being\", \"inferior\", \"squalid\", \"parasitic\", \"parasite\", \"creature\", \"trash\", \"filth\", \"vermin\", \"spider\", \"devil\", \"monster\", \"beast\", \"reptile\", \"reptiloid\", \"femoid\", \"reptilian\", \"snake\", \"cockroach\", \"beneath human skin\", \"sub human\", \"anti-human\", \"disease\", \"savage\", \"infest\", \"breed\", \"locust\", \"monkey\", \"gorilla\", \"rat\", \"microbe\", \"satan\", \"cancer\", \"scum\"]\n",
    "existential_threat = [\"subjected to\", \"coerced\", \"brainwashed\", \"exterminated\", \"brutalised\", \"raped\", \"terrorised\", \"ravaged\", \"extinction\", \"replacement\", \"genocide\", \"robbed\", \"subjugate\", \"make war upon my people\", \"destroy\", \"subvert\", \"overwhelmed\", \"under siege\", \"demographic siege\", \"disenfranchise\", \"assault\", \"kill us\", \"kill our\", \"kill my\", \"running out of time\", \"run out of time\", \"last chance\", \"enslavement\", \"enslaved\", \"suffer\", \"plunder\", \"condemned to death\", \"destruction of all mankind\", \"at the brink of\", \"endanger\", \"annihilation\", \"decay\"]\n",
    "conspiracy = [\"betray\", \"betrayal\", \"sell\", \"sold\", \"collude\", \"conspire\", \"fake\", \"fraud\", \"corruption\", \"corrupt\", \"zog\", \"great replacement\", \"white genocide\", \"kalergi\", \"pedo elites\", \"NWO\", \"illuminati\", \"inside job\", \"Eurabia\"]\n",
    "inevitable_war1 = [\"war\", \"battle\", \"fight\", \"jihad\", \"jihaad\", \"collapse\", \"conflict\"]\n",
    "inevitable_war2 = [\"imminent\", \"inevitable\", \"looming\", \"start\", \"begin\", \"already\", \"heading for\", \"ongoing\", \"stage\", \"phase\", \"when\", \"has been\", \"likely\", \"predict\", \"expect\", \"will happen\", \"has begun\", \"current\", \"impending\"]\n",
    "violence_justification = [\"pre-emptive\", \"defend\", \"protect\", \"self-defense\", \"self-defence\", \"forced to fight\", \"no longer ignore\", \"act of defense\", \"purified\", \"purify\", \"need for war\", \"need for violence\", \"need for jihad\", \"struggle is imposed\", \"natural struggle\", \"cannot co-exist\"]\n",
    "martyr = [\"die in glory\", \"sacrifice\", \"knight\", \"martyr\", \"die selflessly\", \"protecting our people\", \"immortal\", \"preserve\", \"act of preservation\", \"defend the world of the Lord\", \"defending the work of the Lord\", \"stand guard\", \"standing guard\", \"the herald\", \"release mankind from\", \"free from\", \"freed from\"]\n",
    "violent_role_model1 = [\"breivik\", \"tarrant\", \"hitler\", \"crusius\", \"rodger\", \"baillet\", \"earnest\", \"minassian\", \"mcveigh\", \"christchurch\", \"poway\", \"el paso\"]\n",
    "violent_role_model2 = [\"hero\", \"role model\", \"saint\", \"inspire\", \"inspiration\", \"inspiring\", \"support\", \"influenced\"]\n",
    "hopelessness1 = [\"democracy\", \"democratic\", \"peaceful\", \"political\", \"system\", \"politics\", \"dialogue\", \"passivity\"]\n",
    "hopelessness2 = [\"meaningless\", \"weak\", \"fail\", \"end\", \"vanish\", \"man-made\", \"flawed\", \"jahili\", \"given up\"]\n",
    "# Add other dictionaries if needed, similar to the ones above\n",
    "\n",
    "# Add all dictionaries to a list for easier processing\n",
    "dictionaries = {\n",
    "    'fusion': fusion,\n",
    "    'violence': violence,\n",
    "    'identification1': identification1,\n",
    "    'identification2': identification2,\n",
    "    'slurs': slurs,\n",
    "    'demonisation': demonisation,\n",
    "    'dehumanisation': dehumanisation,\n",
    "    'existential_threat': existential_threat,\n",
    "    'conspiracy': conspiracy,\n",
    "    'inevitable_war1': inevitable_war1,\n",
    "    'inevitable_war2': inevitable_war2,\n",
    "    'violence_justification': violence_justification,\n",
    "    'martyr': martyr,\n",
    "    'violent_role_model1': violent_role_model1,\n",
    "    'violent_role_model2': violent_role_model2,\n",
    "    'hopelessness1': hopelessness1,\n",
    "    'hopelessness2': hopelessness2\n",
    "}\n",
    "\n",
    "# Pre-compile regex patterns for each dictionary to improve performance\n",
    "compiled_patterns = {\n",
    "    category: [re.compile(rf'\\b{re.escape(word)}\\b') for word in words_list]\n",
    "    for category, words_list in dictionaries.items()\n",
    "}\n",
    "\n",
    "# Clean text by removing stopwords and lowering the case\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = ''\n",
    "    words = text.split()\n",
    "    cleaned_words = [word.lower() for word in words if word.lower() not in nltk_stopwords]\n",
    "    return ' '.join(cleaned_words)\n",
    "\n",
    "# Count keyword matches per dictionary\n",
    "def count_categories(text):\n",
    "    category_counts = {category: 0 for category in dictionaries}\n",
    "    for category, patterns in compiled_patterns.items():\n",
    "        for pattern in patterns:\n",
    "            if pattern.search(text):\n",
    "                category_counts[category] += 1\n",
    "    return category_counts\n",
    "\n",
    "# Count number of tokens (words)\n",
    "def count_tokens(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Count number of tokens in raw text\n",
    "def count_raw_tokens(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "# Clean the content column\n",
    "df['content_cleaned'] = df['content'].apply(clean_text)\n",
    "\n",
    "# Count category occurrences\n",
    "df['content_category_counts'] = df['content_cleaned'].apply(count_categories)\n",
    "\n",
    "# Token counts\n",
    "df['content_token_count_cleaned'] = df['content_cleaned'].apply(count_tokens)\n",
    "df['content_token_count_raw'] = df['content'].apply(count_raw_tokens)\n",
    "\n",
    "# Totals\n",
    "total_tokens_raw = df['content_token_count_raw'].sum()\n",
    "total_tokens_cleaned = df['content_token_count_cleaned'].sum()\n",
    "\n",
    "# Output\n",
    "print(f\"Total number of tokens in 'content' BEFORE cleaning: {total_tokens_raw}\")\n",
    "print(f\"Total number of tokens in 'content' AFTER cleaning: {total_tokens_cleaned}\")\n",
    "\n",
    "# Summed category counts\n",
    "combined_category_counts_total = df['content_category_counts'].apply(pd.Series).sum()\n",
    "print(\"Total combined category counts in 'content' column:\")\n",
    "print(combined_category_counts_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning: 6494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /uufs/chpc.utah.edu/common/home/u1472278/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/uufs/chpc.utah.edu/common/home/u1472278/miniconda3/envs/new_env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cleaning: 6285\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "# Download NLTK stopwords if you haven't already\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load NLTK English stopwords\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = ''\n",
    "    words = text.split()\n",
    "    # Remove stopwords and lower-case each word\n",
    "    cleaned_words = [word.lower() for word in words if word.lower() not in nltk_stopwords]\n",
    "    return ' '.join(cleaned_words)\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    # Clean the \"content\" column and store in \"content_cleaned\"\n",
    "    chunk['content_cleaned'] = chunk['content'].apply(clean_text)\n",
    "    return chunk\n",
    "\n",
    "def multiprocess_dataframe(df, num_partitions=4):\n",
    "    # Split the DataFrame and process in parallel\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    with Pool(num_partitions) as pool:\n",
    "        df_chunks = pool.map(process_chunk, df_split)\n",
    "    return pd.concat(df_chunks).reset_index(drop=True)\n",
    "\n",
    "def process_dataset(file_path):\n",
    "    # Read the entire CSV file with only the \"content\" column\n",
    "    df = pd.read_csv(file_path, usecols=['content'])\n",
    "    print(\"Rows before cleaning:\", len(df))\n",
    "    \n",
    "    # Remove rows with missing or empty \"content\"\n",
    "    df = df.dropna(subset=['content'])\n",
    "    df['content'] = df['content'].astype(str)\n",
    "    df = df[df['content'].str.strip() != '']\n",
    "    \n",
    "    # Remove rows containing links\n",
    "    df = df[~df['content'].str.contains(r'http[s]?://\\S+', na=False)]\n",
    "    \n",
    "    # Process the DataFrame in parallel to clean the \"content\" text\n",
    "    df_processed = multiprocess_dataframe(df, num_partitions=4)\n",
    "    print(\"Rows after cleaning:\", len(df_processed))\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Execute the function on the dataset\n",
    "processed_df = process_dataset(\"/scratch/general/vast/u1472278/comments_range.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
